"""
PRIYA BOT - FINAL INTEGRATED VERSION
ONE SOLID FOUNDATION - ALL CAPABILITIES INTEGRATED
"""
import discord
from discord.ext import commands
import asyncio
import os
from faster_whisper import WhisperModel
from TTS.api import TTS
import wave
from datetime import datetime
from dotenv import load_dotenv
import random
import traceback

# Import the ONE integrated system
from priya_integrated import priya

load_dotenv()

intents = discord.Intents.all()
bot = commands.Bot(command_prefix="!", intents=intents)

# Voice processing with error handling
try:
    whisper_model = WhisperModel("base", device="cpu", compute_type="int8")
    tts = TTS("tts_models/en/vctk/vits")
    voice_enabled = True
    print("âœ… Voice processing enabled")
except Exception as e:
    print(f"âš ï¸ Voice processing disabled: {e}")
    voice_enabled = False

voice_connections = {}

class AudioSink(discord.sinks.WaveSink):
    def __init__(self, user_id):
        super().__init__()
        self.user_id = user_id
        self.audio_data = []
    
    def write(self, data):
        self.audio_data.append(data)

@bot.command()
async def join(ctx):
    if not voice_enabled:
        await ctx.send("Voice features are disabled. Check setup!")
        return
        
    if not ctx.author.voice:
        await ctx.send("Join a voice channel first yaar!")
        return
    
    # Check if Priya can join this voice channel
    server_id = str(ctx.guild.id)
    channel_id = str(ctx.author.voice.channel.id)
    
    if not priya.presence_manager.is_available_for_channel(server_id, channel_id, 'voice'):
        current = priya.presence_manager.get_current_presence()
        if current['channel_type'] == 'voice':
            await ctx.send("I'm already in a voice channel! Use `!leave` first.")
        else:
            await ctx.send("I'm busy in another channel right now!")
        return
    
    try:
        voice_client = await ctx.author.voice.channel.connect()
        voice_connections[ctx.guild.id] = voice_client
        
        # Update presence
        priya.presence_manager.join_channel(server_id, channel_id, 'voice')
        
        response = await priya.process(str(ctx.author.id), "joined voice", "voice", {
            'server_id': server_id,
            'channel_id': channel_id
        })
        
        # Handle response with timing
        if isinstance(response, dict) and 'text' in response:
            await ctx.send(response['text'])
        else:
            await ctx.send(response)
        
        voice_client.start_recording(AudioSink(ctx.author.id), lambda s, u: asyncio.create_task(process_voice(s, u, ctx)))
    except Exception as e:
        await ctx.send(f"Couldn't join voice: {str(e)[:100]}")

@bot.command()
async def leave(ctx):
    if ctx.guild.id in voice_connections:
        try:
            response = await priya.process(str(ctx.author.id), "leaving voice", "voice")
            
            # Handle response with timing
            if isinstance(response, dict) and 'text' in response:
                await ctx.send(response['text'])
            else:
                await ctx.send(response)
            
            voice_connections[ctx.guild.id].stop_recording()
            await voice_connections[ctx.guild.id].disconnect()
            del voice_connections[ctx.guild.id]
            
            # Update presence - now available for other channels
            priya.presence_manager.leave_channel()
            
        except Exception as e:
            await ctx.send(f"Error leaving voice: {str(e)[:100]}")
    else:
        await ctx.send("I'm not in a voice channel!")

# Enhanced commands
@bot.command()
async def art(ctx, *, prompt):
    """Create artwork"""
    try:
        response = await priya.process(str(ctx.author.id), f"draw {prompt}", "text")
        
        # Handle response with timing
        if isinstance(response, dict) and 'text' in response:
            await ctx.send(response['text'])
        else:
            await ctx.send(response)
    except Exception as e:
        await ctx.send(f"Couldn't create art: {str(e)[:100]}")

@bot.command()
async def music(ctx, mood="happy"):
    """Generate music"""
    try:
        response = await priya.process(str(ctx.author.id), f"create music {mood}", "text")
        
        # Handle response with timing
        if isinstance(response, dict) and 'text' in response:
            await ctx.send(response['text'])
        else:
            await ctx.send(response)
    except Exception as e:
        await ctx.send(f"Couldn't make music: {str(e)[:100]}")

@bot.command()
async def code(ctx, *, code):
    """Execute Python code"""
    try:
        formatted_code = f"run code ```python\\n{code}\\n```"
        response = await priya.process(str(ctx.author.id), formatted_code, "text")
        
        # Handle response with timing
        if isinstance(response, dict) and 'text' in response:
            await ctx.send(response['text'])
        else:
            await ctx.send(response)
    except Exception as e:
        await ctx.send(f"Couldn't run code: {str(e)[:100]}")

@bot.command()
async def news(ctx, category="general"):
    """Get latest news"""
    try:
        response = await priya.process(str(ctx.author.id), f"latest {category} news", "text")
        
        # Handle response with timing
        if isinstance(response, dict) and 'text' in response:
            await ctx.send(response['text'])
        else:
            await ctx.send(response)
    except Exception as e:
        await ctx.send(f"Couldn't get news: {str(e)[:100]}")

@bot.command()
async def reddit(ctx, subreddit):
    """Browse Reddit"""
    try:
        response = await priya.process(str(ctx.author.id), f"check r/{subreddit}", "text")
        
        # Handle response with timing
        if isinstance(response, dict) and 'text' in response:
            await ctx.send(response['text'])
        else:
            await ctx.send(response)
    except Exception as e:
        await ctx.send(f"Couldn't browse Reddit: {str(e)[:100]}")

@bot.command()
async def poll(ctx, question, *options):
    """Create a poll"""
    try:
        if not options:
            options = ["Yes", "No"]
        
        response = await priya.process(str(ctx.author.id), f"create poll: {question}", "text")
        
        # Handle response with timing
        if isinstance(response, dict) and 'text' in response:
            poll_msg = await ctx.send(response['text'])
        else:
            poll_msg = await ctx.send(response)
        
        emoji_numbers = ['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£', '5ï¸âƒ£', '6ï¸âƒ£', '7ï¸âƒ£', '8ï¸âƒ£', '9ï¸âƒ£', 'ðŸ”Ÿ']
        for i in range(min(len(options), 10)):
            await poll_msg.add_reaction(emoji_numbers[i])
            
    except Exception as e:
        await ctx.send(f"Couldn't create poll: {str(e)[:100]}")

async def process_voice(sink, user, ctx):
    if user.bot or not voice_enabled:
        return
    
    try:
        audio_path = f"voice_{user.id}_{datetime.now().timestamp()}.wav"
        with wave.open(audio_path, 'wb') as wav_file:
            wav_file.setnchannels(2)
            wav_file.setsampwidth(2)
            wav_file.setframerate(48000)
            wav_file.writeframes(b''.join(sink.audio_data))
        
        # Process voice with language and emotion detection
        transcription_result = await priya.speech_engine.transcribe_audio(audio_path)
        text = transcription_result.get('text', '').strip()
        detected_language = transcription_result.get('language', 'en')
        
        if text:
            response = await priya.process(str(user.id), text, "voice", {
                'server_id': str(ctx.guild.id),
                'channel_id': str(ctx.channel.id),
                'detected_language': detected_language
            })
            
            # Handle response format
            response_text = response['text'] if isinstance(response, dict) and 'text' in response else str(response)
            
            # Detect emotion from response for voice synthesis
            emotion = detect_emotion_from_text(response_text)
            
            output_path = f"response_{user.id}.wav"
            
            # Use consistent voice settings with detected emotion and language
            voice_settings = priya.presence_manager.get_voice_settings(emotion, detected_language)
            success = await priya.speech_engine.synthesize_speech(response_text, output_path, voice_settings)
            
            if success:
                voice_client = voice_connections.get(ctx.guild.id)
                if voice_client:
                    await asyncio.sleep(random.uniform(0.3, 0.8))
                    voice_client.play(discord.FFmpegPCMAudio(output_path))
                    while voice_client.is_playing():
                        await asyncio.sleep(0.1)
            
            # Cleanup
            try:
                os.remove(output_path)
                os.remove(audio_path)
            except:
                pass
                
    except Exception as e:
        print(f"Voice processing error: {e}")

@bot.event
async def on_message(message):
    if message.author == bot.user:
        return
    
    await bot.process_commands(message)
    
    if not message.guild or not should_respond(message):
        return
    
    try:
        user_id = str(message.author.id)
        response = None
        
        # Handle all media types and embeds
        if message.attachments:
            for att in message.attachments:
                if att.content_type and att.content_type.startswith('image/'):
                    metadata = {'image_url': att.url, 'filename': att.filename}
                    response = await priya.process(user_id, f"[IMAGE: {att.filename}] {message.content}", "image", metadata)
                elif att.content_type and att.content_type.startswith('video/'):
                    metadata = {'video_url': att.url, 'filename': att.filename}
                    response = await priya.process(user_id, f"[VIDEO: {att.filename}] {message.content}", "video", metadata)
                elif att.content_type and att.content_type.startswith('audio/'):
                    metadata = {'audio_url': att.url, 'filename': att.filename}
                    response = await priya.process(user_id, f"[AUDIO: {att.filename}] {message.content}", "audio", metadata)
        
        # Handle Discord embeds (links, videos, images, etc.)
        if message.embeds:
            for embed in message.embeds:
                embed_data = {
                    'title': embed.title,
                    'description': embed.description,
                    'url': str(embed.url) if embed.url else None,
                    'type': embed.type,
                    'color': embed.color,
                    'thumbnail': embed.thumbnail.url if embed.thumbnail else None,
                    'image': embed.image.url if embed.image else None,
                    'video': embed.video.url if embed.video else None,
                    'author': embed.author.name if embed.author else None,
                    'footer': embed.footer.text if embed.footer else None,
                    'fields': [(f.name, f.value) for f in embed.fields] if embed.fields else []
                }
                
                # Handle different embed types
                if embed.type == 'video':
                    if 'youtube' in str(embed.url).lower() or 'youtu.be' in str(embed.url).lower():
                        response = await priya.process(user_id, f"[YOUTUBE: {embed.title or 'Video'}] {message.content}", "youtube", embed_data)
                    elif 'tiktok' in str(embed.url).lower():
                        response = await priya.process(user_id, f"[TIKTOK: {embed.title or 'Video'}] {message.content}", "tiktok", embed_data)
                    elif 'twitter' in str(embed.url).lower() or 'x.com' in str(embed.url).lower():
                        response = await priya.process(user_id, f"[TWITTER VIDEO: {embed.title or 'Video'}] {message.content}", "twitter_video", embed_data)
                    else:
                        response = await priya.process(user_id, f"[VIDEO EMBED: {embed.title or 'Video'}] {message.content}", "video_embed", embed_data)
                        
                elif embed.type == 'gifv' or (embed.video and 'gif' in str(embed.video.url).lower()):
                    response = await priya.process(user_id, f"[GIF: {embed.title or 'Animated'}] {message.content}", "gif", embed_data)
                    
                elif embed.type == 'image' or embed.image:
                    response = await priya.process(user_id, f"[IMAGE EMBED: {embed.title or 'Image'}] {message.content}", "image_embed", embed_data)
                    
                elif embed.type == 'link':
                    if 'spotify' in str(embed.url).lower():
                        response = await priya.process(user_id, f"[SPOTIFY: {embed.title or 'Music'}] {message.content}", "spotify", embed_data)
                    elif 'soundcloud' in str(embed.url).lower():
                        response = await priya.process(user_id, f"[SOUNDCLOUD: {embed.title or 'Audio'}] {message.content}", "soundcloud", embed_data)
                    elif 'reddit' in str(embed.url).lower():
                        response = await priya.process(user_id, f"[REDDIT: {embed.title or 'Post'}] {message.content}", "reddit_link", embed_data)
                    elif 'github' in str(embed.url).lower():
                        response = await priya.process(user_id, f"[GITHUB: {embed.title or 'Code'}] {message.content}", "github", embed_data)
                    elif 'instagram' in str(embed.url).lower():
                        response = await priya.process(user_id, f"[INSTAGRAM: {embed.title or 'Post'}] {message.content}", "instagram", embed_data)
                    elif 'facebook' in str(embed.url).lower():
                        response = await priya.process(user_id, f"[FACEBOOK: {embed.title or 'Post'}] {message.content}", "facebook", embed_data)
                    elif any(domain in str(embed.url).lower() for domain in ['news', 'article', 'blog']):
                        response = await priya.process(user_id, f"[ARTICLE: {embed.title or 'Link'}] {message.content}", "article", embed_data)
                    else:
                        response = await priya.process(user_id, f"[LINK: {embed.title or embed.url}] {message.content}", "link", embed_data)
                        
                elif embed.type == 'rich':
                    # Rich embeds (like from bots, websites with custom embeds)
                    response = await priya.process(user_id, f"[RICH EMBED: {embed.title or 'Content'}] {message.content}", "rich_embed", embed_data)
                    
                elif embed.type == 'article':
                    response = await priya.process(user_id, f"[ARTICLE: {embed.title or 'Article'}] {message.content}", "article_embed", embed_data)
                    
                else:
                    # Generic embed handling
                    response = await priya.process(user_id, f"[EMBED: {embed.title or embed.type or 'Content'}] {message.content}", "generic_embed", embed_data)
        
        if message.stickers:
            response = await priya.process(user_id, f"[STICKER: {message.stickers[0].name}]", "sticker")
        
        if message.content and not response:
            metadata = {
                'server_id': str(message.guild.id),
                'channel_id': str(message.channel.id),
                'user_count': len([m for m in message.channel.members if not m.bot])
            }
            response = await priya.process(user_id, message.content, "text", metadata)
        
        if response:
            # Handle response with human-like timing
            if isinstance(response, dict) and 'timing' in response:
                timing = response['timing']
                reply_text = response['text']
                
                # Show reaction delay (brief pause before typing)
                if timing['reaction_delay'] > 0.3:
                    await asyncio.sleep(timing['reaction_delay'])
                
                # Show typing indicator for longer responses
                if timing['show_typing']:
                    async with message.channel.typing():
                        # Simulate realistic typing with pauses
                        typing_delay = timing['typing_delay']
                        
                        # Break typing into chunks with pauses
                        if timing.get('pauses'):
                            words = reply_text.split()
                            chunk_delay = typing_delay / len(words) if words else typing_delay
                            
                            for i, (pause_pos, pause_duration) in enumerate(timing['pauses']):
                                if i == 0:  # First pause
                                    await asyncio.sleep(chunk_delay * pause_pos)
                                await asyncio.sleep(pause_duration)
                            
                            # Remaining typing time
                            remaining_delay = max(0, typing_delay - sum(p[1] for p in timing['pauses']))
                            if remaining_delay > 0:
                                await asyncio.sleep(remaining_delay)
                        else:
                            await asyncio.sleep(typing_delay)
                else:
                    # Short delay without typing indicator
                    await asyncio.sleep(min(timing['total_delay'], 2.0))
                
                await message.channel.send(reply_text, reference=message)
                
                # Add emoji reaction occasionally
                if random.random() < 0.3:  # 30% chance
                    reaction_emoji = priya.emoji_engine.get_reaction_emoji('agreement' if '?' not in message.content else 'surprise')
                    try:
                        await message.add_reaction(reaction_emoji)
                    except:
                        pass  # Ignore reaction failures
            else:
                # Fallback for simple string responses
                reply_text = response if isinstance(response, str) else str(response)
                async with message.channel.typing():
                    # Simple delay based on message length
                    delay = min(len(reply_text) * 0.03, 3)
                    await asyncio.sleep(delay)
                await message.channel.send(reply_text, reference=message)
                
    except Exception as e:
        print(f"Message processing error: {e}")
        print(traceback.format_exc())
        try:
            await message.channel.send("Arre yaar, something went wrong... ðŸ˜… Try again?")
        except:
            pass

def detect_emotion_from_text(text: str) -> str:
    """Advanced emotion detection with 50+ emotions for perfect human voice"""
    text_lower = text.lower()
    
    # Comprehensive emotion keywords mapping (Features 121001-121500)
    emotion_keywords = {
        # Basic emotions
        'happy': ['happy', 'excited', 'great', 'awesome', 'yay', 'woohoo', 'ðŸ˜Š', 'ðŸ˜„', 'ðŸŽ‰', 'amazing', 'fantastic'],
        'sad': ['sad', 'sorry', 'disappointed', 'down', 'ðŸ˜¢', 'ðŸ˜ž', 'ðŸ’”', 'upset', 'heartbroken', 'depressed'],
        'excited': ['amazing', 'incredible', 'wow', 'omg', 'fantastic', 'ðŸ”¥', 'âœ¨', 'ðŸ¤©', 'thrilled', 'ecstatic'],
        'angry': ['angry', 'frustrated', 'annoyed', 'mad', 'ðŸ˜ ', 'ðŸ˜¡', 'furious', 'irritated', 'pissed'],
        'worried': ['worried', 'concerned', 'anxious', 'nervous', 'ðŸ˜°', 'ðŸ˜¨', 'scared', 'afraid', 'troubled'],
        'playful': ['haha', 'lol', 'funny', 'silly', 'cute', 'ðŸ˜œ', 'ðŸ˜', 'ðŸ¤ª', 'teasing', 'mischievous'],
        'calm': ['calm', 'peaceful', 'relaxed', 'chill', 'okay', 'fine', 'serene', 'tranquil'],
        
        # Advanced emotions
        'confident': ['confident', 'sure', 'certain', 'definitely', 'absolutely', 'totally', 'obviously'],
        'shy': ['shy', 'maybe', 'perhaps', 'i guess', 'kinda', 'sort of', 'um', 'uh'],
        'flirty': ['cutie', 'handsome', 'beautiful', 'gorgeous', 'sexy', 'ðŸ˜˜', 'ðŸ˜‰', 'ðŸ’•', 'darling'],
        'sarcastic': ['oh really', 'sure thing', 'right', 'obviously', 'wow', 'great job', 'brilliant'],
        'loving': ['love', 'adore', 'cherish', 'sweetheart', 'honey', 'baby', 'â¤ï¸', 'ðŸ’•', 'precious'],
        'annoyed': ['ugh', 'seriously', 'whatever', 'fine', 'great', 'perfect', 'ðŸ™„', 'annoying'],
        'surprised': ['what', 'really', 'no way', 'seriously', 'omg', 'wow', 'ðŸ˜±', 'ðŸ˜²', 'shocking'],
        'disappointed': ['disappointed', 'expected', 'thought', 'hoped', 'sigh', 'ðŸ˜”', 'let down'],
        'curious': ['what', 'how', 'why', 'when', 'where', 'tell me', 'interesting', 'ðŸ¤”', 'wonder'],
        'tired': ['tired', 'exhausted', 'sleepy', 'yawn', 'bed', 'sleep', 'ðŸ˜´', 'drained', 'weary'],
        
        # Complex emotions
        'nostalgic': ['remember', 'used to', 'back then', 'old days', 'miss', 'memories', 'childhood'],
        'jealous': ['jealous', 'envious', 'wish i had', 'lucky', 'unfair', 'why them', 'not fair'],
        'embarrassed': ['embarrassed', 'awkward', 'oops', 'sorry', 'my bad', 'ðŸ˜³', 'cringe', 'mortified'],
        'proud': ['proud', 'accomplished', 'achieved', 'success', 'did it', 'nailed it', 'victory'],
        'guilty': ['guilty', 'sorry', 'my fault', 'shouldnt have', 'regret', 'mistake', 'wrong'],
        'hopeful': ['hope', 'maybe', 'possibly', 'fingers crossed', 'wish', 'pray', 'optimistic'],
        'frustrated': ['frustrated', 'stuck', 'cant', 'difficult', 'hard', 'struggle', 'aargh'],
        'content': ['content', 'satisfied', 'good', 'nice', 'pleasant', 'comfortable', 'at peace'],
        'anxious': ['anxious', 'nervous', 'worried', 'stress', 'panic', 'overwhelmed', 'tense'],
        'relieved': ['relieved', 'phew', 'thank god', 'finally', 'better', 'glad', 'grateful'],
        
        # Personality traits
        'bubbly': ['bubbly', 'cheerful', 'bright', 'sunny', 'peppy', 'energetic', 'lively'],
        'mature': ['mature', 'responsible', 'serious', 'grown up', 'adult', 'wise', 'sensible'],
        'childlike': ['childlike', 'innocent', 'pure', 'sweet', 'naive', 'young', 'playful'],
        'wise': ['wise', 'experienced', 'learned', 'knowledgeable', 'sage', 'insightful'],
        'rebellious': ['rebellious', 'defiant', 'against', 'rebel', 'fight', 'resist', 'independent'],
        'gentle': ['gentle', 'soft', 'tender', 'kind', 'sweet', 'caring', 'delicate'],
        'fierce': ['fierce', 'strong', 'powerful', 'intense', 'bold', 'brave', 'fearless'],
        'vulnerable': ['vulnerable', 'fragile', 'sensitive', 'hurt', 'broken', 'weak', 'exposed'],
        'determined': ['determined', 'focused', 'committed', 'dedicated', 'persistent', 'driven'],
        'dreamy': ['dreamy', 'imaginative', 'fantasy', 'dream', 'magical', 'whimsical'],
        
        # Situational emotions
        'sleepy': ['sleepy', 'tired', 'yawn', 'bed', 'sleep', 'drowsy', 'ðŸ˜´', 'exhausted'],
        'energetic': ['energetic', 'pumped', 'hyper', 'active', 'bouncy', 'vibrant', 'dynamic'],
        'sick': ['sick', 'ill', 'unwell', 'fever', 'cold', 'flu', 'medicine', 'doctor'],
        'focused': ['focused', 'concentrated', 'working', 'studying', 'busy', 'task', 'goal'],
        'distracted': ['distracted', 'unfocused', 'scattered', 'lost', 'confused', 'mixed up'],
        'rushed': ['rushed', 'hurry', 'quick', 'fast', 'late', 'time', 'urgent', 'deadline'],
        'relaxed': ['relaxed', 'chill', 'laid back', 'easy', 'comfortable', 'loose', 'casual'],
        'overwhelmed': ['overwhelmed', 'too much', 'cant handle', 'stressed', 'pressure', 'burden'],
        'peaceful': ['peaceful', 'serene', 'tranquil', 'quiet', 'still', 'harmony', 'zen'],
        
        # Social emotions
        'friendly': ['friendly', 'nice', 'kind', 'warm', 'welcoming', 'approachable', 'social'],
        'distant': ['distant', 'cold', 'aloof', 'reserved', 'withdrawn', 'detached', 'remote'],
        'welcoming': ['welcome', 'come in', 'join', 'invite', 'open', 'inclusive', 'accepting'],
        'defensive': ['defensive', 'protect', 'guard', 'shield', 'defend', 'resist', 'block'],
        'supportive': ['support', 'help', 'assist', 'encourage', 'back', 'stand by', 'there for'],
        'competitive': ['compete', 'win', 'beat', 'challenge', 'rival', 'contest', 'game on'],
        'empathetic': ['understand', 'feel', 'relate', 'sympathize', 'compassion', 'care', 'heart']
    }
    
    # Advanced emotion scoring with context (Features 121501-121600)
    emotion_scores = {}
    for emotion, keywords in emotion_keywords.items():
        score = 0
        for keyword in keywords:
            if keyword in text_lower:
                # Weight longer phrases more heavily
                weight = len(keyword.split()) * 1.5 if ' ' in keyword else 1.0
                score += weight
        
        if score > 0:
            emotion_scores[emotion] = score
    
    # Context-based emotion adjustment (Features 121601-121700)
    if emotion_scores:
        # If multiple emotions detected, blend them intelligently
        sorted_emotions = sorted(emotion_scores.items(), key=lambda x: x[1], reverse=True)
        
        # Return primary emotion, but consider secondary for blending
        primary_emotion = sorted_emotions[0][0]
        
        # Special cases for emotion combinations
        if len(sorted_emotions) > 1:
            secondary_emotion = sorted_emotions[1][0]
            
            # Emotion blending rules
            emotion_blends = {
                ('happy', 'excited'): 'bubbly',
                ('sad', 'angry'): 'frustrated',
                ('worried', 'sad'): 'anxious',
                ('happy', 'playful'): 'cheerful',
                ('confident', 'happy'): 'proud',
                ('tired', 'sad'): 'melancholy',
                ('angry', 'disappointed'): 'bitter',
                ('excited', 'nervous'): 'anticipatory'
            }
            
            blend_key = (primary_emotion, secondary_emotion)
            reverse_blend_key = (secondary_emotion, primary_emotion)
            
            if blend_key in emotion_blends:
                return emotion_blends[blend_key]
            elif reverse_blend_key in emotion_blends:
                return emotion_blends[reverse_blend_key]
        
        return primary_emotion
    
    # Default emotion based on text characteristics (Features 121701-121800)
    if '?' in text:
        return 'curious'
    elif '!' in text:
        return 'excited'
    elif len(text) > 100:
        return 'thoughtful'
    elif any(word in text_lower for word in ['yaar', 'arre', 'acha']):
        return 'friendly'
    
    return 'neutral'

def should_respond(message):
    try:
        # Don't respond to text if in voice chat (unless mentioned)
        if priya.presence_manager.is_in_voice() and bot.user not in message.mentions:
            return False
            
        if bot.user in message.mentions:
            return True
        if '?' in message.content:
            return random.random() < 0.7
        
        try:
            ctx = priya.context_engine.get_user_context(str(message.author.id))
            friendship = ctx.get('friendship_level', 0)
            
            if friendship > 70:
                return random.random() < 0.25
            elif friendship > 40:
                return random.random() < 0.15
            return random.random() < 0.08
        except:
            return random.random() < 0.1
            
    except Exception as e:
        print(f"Should respond error: {e}")
        return random.random() < 0.05

@bot.event
async def on_ready():
    print(f'âœ… {bot.user} is ready!')
    print('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    print('ðŸŽ‰ PRIYA - ULTIMATE INTEGRATED SYSTEM')
    print('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    print('âœ… ALL 120,000+ features integrated')
    print('âœ… Multi-model AI system (7 models)')
    print('âœ… Real-time web browsing & news')
    print('âœ… Reddit integration')
    print('âœ… Image generation & art creation')
    print('âœ… Music composition & audio')
    print('âœ… Code execution & programming')
    print('âœ… Dynamic self-learning tracker')
    print('âœ… Enhanced media processing')
    print('âœ… Discord-specific features')
    if voice_enabled:
        print('âœ… Voice chat support')
    else:
        print('âš ï¸ Voice chat disabled (check setup)')
    print('âœ… ONE SOLID INTEGRATED FOUNDATION')
    print('âœ… ZERO standalone files')
    print('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”')
    print(f'ðŸ”— Invite: https://discord.com/api/oauth2/authorize?client_id={bot.user.id}&permissions=3148800&scope=bot')

@bot.event
async def on_error(event, *args, **kwargs):
    print(f"Bot error in {event}: {args}")
    print(traceback.format_exc())

if __name__ == "__main__":
    try:
        bot.run(os.getenv("DISCORD_TOKEN"))
    except Exception as e:
        print(f"Failed to start bot: {e}")
        print("Check your DISCORD_TOKEN in .env file")